{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import pickle\n",
    "from time import time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model, load_model, Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_size = 100\n",
    "batch_size = 10\n",
    "epochs = 150\n",
    "frames_in_each_sample = 66\n",
    "frame_shape = (75, 175)  # width, height\n",
    "channels = 3\n",
    "with open('Vectorizor.pkl', 'rb') as file:\n",
    "    vect = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocessing(video_path):\n",
    "    \"\"\"Get Video from video_path\"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    vid = []\n",
    "    while True:\n",
    "        ret, img = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        vid.append(cv2.resize(img, frame_shape, cv2.INTER_AREA))\n",
    "\n",
    "    vid = np.array(vid, dtype=np.float32).reshape(-1,\n",
    "                                                  frame_shape[1],\n",
    "                                                  frame_shape[0],\n",
    "                                                  channels)\n",
    "    new_vid = vid[:frames_in_each_sample]\n",
    "    print(new_vid.shape)\n",
    "    return new_vid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1 (Conv3D)               (None, 66, 175, 75, 64)   5248      \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling3D)         (None, 66, 87, 37, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv3D)               (None, 66, 87, 37, 128)   221312    \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling3D)         (None, 33, 43, 18, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv3a (Conv3D)              (None, 33, 43, 18, 256)   884992    \n",
      "_________________________________________________________________\n",
      "conv3b (Conv3D)              (None, 33, 43, 18, 256)   1769728   \n",
      "_________________________________________________________________\n",
      "pool3 (MaxPooling3D)         (None, 16, 21, 9, 256)    0         \n",
      "_________________________________________________________________\n",
      "conv4a (Conv3D)              (None, 16, 21, 9, 512)    3539456   \n",
      "_________________________________________________________________\n",
      "conv4b (Conv3D)              (None, 16, 21, 9, 512)    7078400   \n",
      "_________________________________________________________________\n",
      "pool4 (MaxPooling3D)         (None, 8, 10, 4, 512)     0         \n",
      "_________________________________________________________________\n",
      "conv5a (Conv3D)              (None, 8, 10, 4, 512)     7078400   \n",
      "_________________________________________________________________\n",
      "conv5b (Conv3D)              (None, 8, 10, 4, 512)     7078400   \n",
      "_________________________________________________________________\n",
      "zero_padding3d_1 (ZeroPaddin (None, 8, 12, 6, 512)     0         \n",
      "_________________________________________________________________\n",
      "pool5 (MaxPooling3D)         (None, 4, 6, 3, 512)      0         \n",
      "_________________________________________________________________\n",
      "Flatten (TimeDistributed)    (None, 4, 9216)           0         \n",
      "_________________________________________________________________\n",
      "LSTM_1 (LSTM)                (None, 4, 400)            15387200  \n",
      "_________________________________________________________________\n",
      "LSTM_2 (LSTM)                (None, 4, 300)            841200    \n",
      "_________________________________________________________________\n",
      "LSTM_3 (LSTM)                (None, 4, 200)            400800    \n",
      "_________________________________________________________________\n",
      "LSTM_4 (LSTM)                (None, 100)               120400    \n",
      "=================================================================\n",
      "Total params: 44,405,536\n",
      "Trainable params: 44,405,536\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = load_model('video_captioning_model.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66, 175, 75, 3)\n",
      "(1, 66, 175, 75, 3)\n",
      "<type 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "test_vid = './test_clips/FRIENDS_WITH_BENEFITS_DVS101.avi'\n",
    "new_vid =  preprocessing(test_vid)\n",
    "new_vid = np.array([new_vid])\n",
    "print(new_vid.shape)\n",
    "print type(new_vid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = model.predict(new_vid, batch_size=1, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Predicted Caption:', 'approaches arm arms away bed black boy brow car chest climbs dark door drops enters eyes face faces father feet finds floor follows forward gaze gazes gets gives glances glass grabs ground gun hair haired hand hands head heads holds house inside kisses later leans leaves lies lifts light lips look looks lowers man men mouth nods open opens outside past peers phone picks pulls puts reaches reads red room runs seat sets shakes shifts shows sits smile smiles stands stares steps stops street table takes turns view walks wall watch watches water wearing white window woman young')\n"
     ]
    }
   ],
   "source": [
    "cap = vect.inverse_transform(temp)\n",
    "print (\"Predicted Caption:\", str(' '.join(cap[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
